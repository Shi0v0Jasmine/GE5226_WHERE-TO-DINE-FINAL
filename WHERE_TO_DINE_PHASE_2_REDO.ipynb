{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas pysal\n",
        "\n",
        "print(\"--- 库安装完成 ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Uhn-DJZEbH",
        "outputId": "b8a23ce5-dd5e-4e88-b7da-853b166ec027"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting pysal\n",
            "  Downloading pysal-25.7-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.12/dist-packages (from pysal) (4.13.5)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from pysal) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from pysal) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from pysal) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.12/dist-packages (from pysal) (1.6.1)\n",
            "Requirement already satisfied: libpysal>=4.13.0 in /usr/local/lib/python3.12/dist-packages (from pysal) (4.13.0)\n",
            "Collecting access>=1.1.9 (from pysal)\n",
            "  Downloading access-1.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting esda>=2.7.1 (from pysal)\n",
            "  Downloading esda-2.8.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal)\n",
            "  Downloading giddy-2.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inequality>=1.1.2 (from pysal)\n",
            "  Downloading inequality-1.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal)\n",
            "  Downloading pointpats-2.5.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting segregation>=2.5.2 (from pysal)\n",
            "  Downloading segregation-2.5.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal)\n",
            "  Downloading spaghetti-1.7.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal)\n",
            "  Downloading mgwr-2.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting momepy>=0.10.0 (from pysal)\n",
            "  Downloading momepy-0.10.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting spglm>=1.1.0 (from pysal)\n",
            "  Downloading spglm-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting spint>=1.0.7 (from pysal)\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spreg>=1.8.3 (from pysal)\n",
            "  Downloading spreg-1.8.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal)\n",
            "  Downloading tobler-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting mapclassify>=2.10.0 (from pysal)\n",
            "  Downloading mapclassify-2.10.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting splot>=1.1.7 (from pysal)\n",
            "  Downloading splot-1.1.7-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting spopt>=0.7.0 (from pysal)\n",
            "  Downloading spopt-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.10->pysal) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.10->pysal) (4.15.0)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal)\n",
            "  Downloading quantecon-0.10.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from inequality>=1.1.2->pysal) (3.10.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.12/dist-packages (from mapclassify>=2.10.0->pysal) (3.5)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.12/dist-packages (from momepy>=0.10.0->pysal) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.10.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->pysal) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->pysal) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->pysal) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->pysal) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->pysal) (3.6.0)\n",
            "Collecting deprecation (from segregation>=2.5.2->pysal)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from segregation>=2.5.2->pysal) (0.13.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from segregation>=2.5.2->pysal) (0.60.0)\n",
            "Collecting rtree>=1.0 (from spaghetti>=1.7.6->pysal)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pulp>=2.8 (from spopt>=0.7.0->pysal)\n",
            "  Downloading pulp-3.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting rasterio (from tobler>=0.12.1->pysal)\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from tobler>=0.12.1->pysal) (0.14.5)\n",
            "Collecting rasterstats (from tobler>=0.12.1->pysal)\n",
            "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (1.13.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->segregation>=2.5.2->pysal) (0.43.0)\n",
            "Collecting affine (from rasterio->tobler>=0.12.1->pysal)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio->tobler>=0.12.1->pysal) (25.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio->tobler>=0.12.1->pysal) (8.3.0)\n",
            "Collecting cligj>=0.5 (from rasterio->tobler>=0.12.1->pysal)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio->tobler>=0.12.1->pysal)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fiona (from rasterstats->tobler>=0.12.1->pysal)\n",
            "  Downloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (3.20.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->tobler>=0.12.1->pysal) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal) (1.3.0)\n",
            "Downloading pysal-25.7-py3-none-any.whl (17 kB)\n",
            "Downloading access-1.1.9-py3-none-any.whl (21 kB)\n",
            "Downloading esda-2.8.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.1/157.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inequality-1.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading mapclassify-2.10.0-py3-none-any.whl (882 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m882.2/882.2 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading momepy-0.10.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pointpats-2.5.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Downloading spopt-0.7.0-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.1/248.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spreg-1.8.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Downloading pulp-3.3.0-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantecon-0.10.1-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.7/325.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spint\n",
            "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31354 sha256=04d8d1bf9515cbbb3095a82bafa3a682add3145cf420ce0f10e97c24e2ad5b6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/82/ea/d31b72061cd6dc1760ec44a1d3e74408b1e6ca590a3361d3f9\n",
            "Successfully built spint\n",
            "Installing collected packages: rtree, pulp, deprecation, cligj, click-plugins, affine, rasterio, quantecon, fiona, rasterstats, mapclassify, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal\n",
            "Successfully installed access-1.1.9 affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 deprecation-2.1.0 esda-2.8.0 fiona-1.10.1 giddy-2.3.6 inequality-1.1.2 mapclassify-2.10.0 mgwr-2.2.1 momepy-0.10.0 pointpats-2.5.2 pulp-3.3.0 pysal-25.7 quantecon-0.10.1 rasterio-1.4.3 rasterstats-0.20.0 rtree-1.4.1 segregation-2.5.2 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.7.0 spreg-1.8.3 tobler-0.12.1\n",
            "--- 库安装完成 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCHlULReY-eS",
        "outputId": "f6451333-2971-4028-cc34-bd6e9a6f3725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 库导入完成 ---\n",
            "--- 正在挂载 Google Drive ---\n",
            "Mounted at /content/drive\n",
            "--- Google Drive 已成功挂载 ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter # <--- 用于高效聚合计数\n",
        "import glob  # 用于查找所有 parquet 文件\n",
        "import libpysal.weights as lw # 用于空间权重\n",
        "import esda # 用于空间统计\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"--- 库导入完成 ---\")\n",
        "\n",
        "# 挂载 Google Drive\n",
        "print(\"--- 正在挂载 Google Drive ---\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"--- Google Drive 已成功挂载 ---\")\n",
        "except Exception as e:\n",
        "    print(f\"!!! 挂载 Google Drive 失败: {e} !!!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------\n",
        "# 单元格 2: (脚本 A) 生成加权热点区域\n",
        "# -----------------------------------------------\n",
        "print(\"--- 开始执行脚本 A: 生成加权热点区域 ---\")\n",
        "\n",
        "# --- 1. 定义权重 (来自 temporal_weighting.md) ---\n",
        "W_LUNCH = 1.0\n",
        "W_WKDY_EVE = 1.2\n",
        "W_WKND_EVE = 1.5\n",
        "print(f\"--- 权重已设置: 午餐={W_LUNCH}, 工作日晚餐={W_WKDY_EVE}, 周末晚餐={W_WKND_EVE} ---\")\n",
        "\n",
        "# --- 2. 加载 Taxi Zones ---\n",
        "TAXI_ZONES_PATH = \"/content/drive/MyDrive/Where-to-dine-demo/data/external/boundaries/taxi_zones.shp\"\n",
        "try:\n",
        "    zones_gdf = gpd.read_file(TAXI_ZONES_PATH)\n",
        "    if 'location_i' in zones_gdf.columns: # 处理列名不一致\n",
        "        zones_gdf.rename(columns={'location_i': 'LocationID'}, inplace=True)\n",
        "    zones_gdf['LocationID'] = zones_gdf['LocationID'].astype(int)\n",
        "    print(f\"--- 成功加载 {len(zones_gdf)} 个 Taxi Zones ---\")\n",
        "except Exception as e:\n",
        "    print(f\"!!! 致命错误: 加载 Taxi Zones 文件失败: {e} !!!\")\n",
        "    # 如果 taxi_zones 失败，则停止\n",
        "    # raise e\n",
        "\n",
        "# --- 3. 初始化三个计数器 ---\n",
        "location_id_counts_lunch = Counter()\n",
        "location_id_counts_wkdy_eve = Counter()\n",
        "location_id_counts_wknd_eve = Counter()\n",
        "\n",
        "# --- 4. 循环处理所有 Parquet 文件 ---\n",
        "TAXI_DATA_PATH = \"/content/drive/MyDrive/Where-to-dine-demo/data/raw/taxi/\"\n",
        "search_pattern = os.path.join(TAXI_DATA_PATH, '*.parquet')\n",
        "parquet_files = glob.glob(search_pattern)\n",
        "\n",
        "if not parquet_files:\n",
        "    print(f\"!!! 错误：在路径 {TAXI_DATA_PATH} 中未找到任何 '.parquet' 文件。\")\n",
        "else:\n",
        "    print(f\"--- 将处理 {len(parquet_files)} 个 Parquet 文件... ---\")\n",
        "\n",
        "    for file_num, file_path in enumerate(parquet_files, 1):\n",
        "        print(f\"  > 正在处理文件 {file_num}/{len(parquet_files)}: {os.path.basename(file_path)}\")\n",
        "        try:\n",
        "            df = pd.read_parquet(file_path)\n",
        "\n",
        "            # 重命名和检查列\n",
        "            df.rename(columns={'DOLocationID': 'do_location_id', 'tpep_dropoff_datetime': 'dropoff_datetime'}, inplace=True, errors='ignore')\n",
        "            if 'do_location_id' not in df.columns or 'dropoff_datetime' not in df.columns:\n",
        "                print(f\"    > 跳过: 缺少 'do_location_id' 或 'dropoff_datetime' 列。\")\n",
        "                continue\n",
        "\n",
        "            # 转换日期并创建时间特征\n",
        "            df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])\n",
        "            df['hour'] = df['dropoff_datetime'].dt.hour\n",
        "            df['day_of_week'] = df['dropoff_datetime'].dt.dayofweek # 0=周一, 6=周日\n",
        "\n",
        "            # --- 核心加权逻辑 (基于 temporal_weighting.md) ---\n",
        "            is_lunch = (df['hour'] >= 11) & (df['hour'] <= 14)\n",
        "            is_wkdy_eve = (df['day_of_week'] < 5) & (df['hour'] >= 17) & (df['hour'] <= 21)\n",
        "            is_wknd_eve = (df['day_of_week'] >= 5) & (df['hour'] >= 17) & (df['hour'] <= 21)\n",
        "\n",
        "            # 分别计数\n",
        "            lunch_counts = df[is_lunch]['do_location_id'].value_counts()\n",
        "            wkdy_eve_counts = df[is_wkdy_eve]['do_location_id'].value_counts()\n",
        "            wknd_eve_counts = df[is_wknd_eve]['do_location_id'].value_counts()\n",
        "\n",
        "            # 更新全局计数器\n",
        "            location_id_counts_lunch.update(lunch_counts.to_dict())\n",
        "            location_id_counts_wkdy_eve.update(wkdy_eve_counts.to_dict())\n",
        "            location_id_counts_wknd_eve.update(wknd_eve_counts.to_dict())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    > 处理文件 {file_path} 时出错: {e}\")\n",
        "\n",
        "    print(\"--- 所有 Parquet 文件处理完毕 ---\")\n",
        "\n",
        "    # --- 5. 聚合和计算加权分数 ---\n",
        "    df_lunch = pd.DataFrame.from_dict(location_id_counts_lunch, orient='index', columns=['Count_Lunch'])\n",
        "    df_wkdy_eve = pd.DataFrame.from_dict(location_id_counts_wkdy_eve, orient='index', columns=['Count_WkdyEve'])\n",
        "    df_wknd_eve = pd.DataFrame.from_dict(location_id_counts_wknd_eve, orient='index', columns=['Count_WkndEve'])\n",
        "\n",
        "    # 合并所有 DataFrame\n",
        "    df_counts = df_lunch.join(df_wkdy_eve, how='outer').join(df_wknd_eve, how='outer')\n",
        "    df_counts.index.name = 'LocationID'\n",
        "    df_counts.index = df_counts.index.astype(int)\n",
        "\n",
        "    # 合并到地理文件\n",
        "    gdf_weighted = zones_gdf.merge(df_counts, on='LocationID', how='left')\n",
        "\n",
        "    # 填充 NaNs 为 0\n",
        "    count_cols = ['Count_Lunch', 'Count_WkdyEve', 'Count_WkndEve']\n",
        "    gdf_weighted[count_cols] = gdf_weighted[count_cols].fillna(0)\n",
        "\n",
        "    # *** 计算加权分数 ***\n",
        "    gdf_weighted['weighted_score'] = (\n",
        "        (gdf_weighted['Count_Lunch'] * W_LUNCH) +\n",
        "        (gdf_weighted['Count_WkdyEve'] * W_WKDY_EVE) +\n",
        "        (gdf_weighted['Count_WkndEve'] * W_WKND_EVE)\n",
        "    )\n",
        "\n",
        "    print(\"--- 加权分数计算完成 ---\")\n",
        "\n",
        "    # --- 6. 运行 Pysal (在 'weighted_score' 上) ---\n",
        "    print(\"--- 正在 'weighted_score' 上运行 Pysal (Getis-Ord Gi*)... ---\")\n",
        "    try:\n",
        "        W = lw.Queen.from_dataframe(gdf_weighted)\n",
        "        y = gdf_weighted['weighted_score']\n",
        "        g_local = esda.G_Local(y, W)\n",
        "\n",
        "        gdf_weighted['Zs'] = g_local.Zs\n",
        "        gdf_weighted['p_sim'] = g_local.p_sim\n",
        "\n",
        "        # 过滤热点\n",
        "        hotspots_gdf = gdf_weighted[\n",
        "            (gdf_weighted['Zs'] > 1.96) & (gdf_weighted['p_sim'] < 0.05)\n",
        "        ]\n",
        "\n",
        "        OUTPUT_FILE_A = \"hotspot_arrival_areas_weighted.geojson\"\n",
        "        hotspots_gdf.to_file(OUTPUT_FILE_A, driver=\"GeoJSON\")\n",
        "\n",
        "        print(f\"\\n--- 成功！脚本 A 已完成 ---\")\n",
        "        print(f\"识别出 {len(hotspots_gdf)} 个加权热点区域。\")\n",
        "        print(f\"结果已保存到: {OUTPUT_FILE_A}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Pysal 分析失败: {e} !!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUsXw515Zozf",
        "outputId": "9c0fe8f8-fccb-4a7e-dfb0-8939b23355f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 开始执行脚本 A: 生成加权热点区域 ---\n",
            "--- 权重已设置: 午餐=1.0, 工作日晚餐=1.2, 周末晚餐=1.5 ---\n",
            "--- 成功加载 263 个 Taxi Zones ---\n",
            "--- 将处理 12 个 Parquet 文件... ---\n",
            "  > 正在处理文件 1/12: yellow_tripdata_2024-07.parquet\n",
            "  > 正在处理文件 2/12: yellow_tripdata_2024-08.parquet\n",
            "  > 正在处理文件 3/12: yellow_tripdata_2024-09.parquet\n",
            "  > 正在处理文件 4/12: yellow_tripdata_2024-10.parquet\n",
            "  > 正在处理文件 5/12: yellow_tripdata_2024-11.parquet\n",
            "  > 正在处理文件 6/12: yellow_tripdata_2024-12.parquet\n",
            "  > 正在处理文件 7/12: yellow_tripdata_2024-01.parquet\n",
            "  > 正在处理文件 8/12: yellow_tripdata_2024-02.parquet\n",
            "  > 正在处理文件 9/12: yellow_tripdata_2024-03.parquet\n",
            "  > 正在处理文件 10/12: yellow_tripdata_2024-04.parquet\n",
            "  > 正在处理文件 11/12: yellow_tripdata_2024-05.parquet\n",
            "  > 正在处理文件 12/12: yellow_tripdata_2024-06.parquet\n",
            "--- 所有 Parquet 文件处理完毕 ---\n",
            "--- 加权分数计算完成 ---\n",
            "--- 正在 'weighted_score' 上运行 Pysal (Getis-Ord Gi*)... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3584546359.py:105: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  W = lw.Queen.from_dataframe(gdf_weighted)\n",
            "/usr/local/lib/python3.12/dist-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
            " There are 10 disconnected components.\n",
            " There are 6 islands with ids: 0, 45, 102, 103, 104, 201.\n",
            "  W.__init__(self, neighbors, ids=ids, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/esda/getisord.py:527: RuntimeWarning: invalid value encountered in divide\n",
            "  z_scores = (statistic - expected_value) / np.sqrt(expected_variance)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('WARNING: ', 0, ' is an island (no neighbors)')\n",
            "('WARNING: ', 45, ' is an island (no neighbors)')\n",
            "('WARNING: ', 102, ' is an island (no neighbors)')\n",
            "('WARNING: ', 103, ' is an island (no neighbors)')\n",
            "('WARNING: ', 104, ' is an island (no neighbors)')\n",
            "('WARNING: ', 201, ' is an island (no neighbors)')\n",
            "\n",
            "--- 成功！脚本 A 已完成 ---\n",
            "识别出 23 个加权热点区域。\n",
            "结果已保存到: hotspot_arrival_areas_weighted.geojson\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/esda/getisord.py:450: RuntimeWarning: invalid value encountered in divide\n",
            "  self.z_sim = (self.Gs - self.EG_sim) / self.seG_sim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------\n",
        "# 单元格 3: (脚本 B & C) 生成最终多边形和餐厅数据库\n",
        "# -----------------------------------------------\n",
        "\n",
        "# --- (脚本 B) 识别 C: 最终热点餐饮区 ---\n",
        "print(\"\\n--- 开始执行脚本 B: 生成最终热点多边形 ---\")\n",
        "\n",
        "FILE_DINING_ZONES = \"dining_zones.geojson\"\n",
        "FILE_HOTSPOT_ARRIVALS_WEIGHTED = \"hotspot_arrival_areas_weighted.geojson\"\n",
        "OUTPUT_FILE_B = \"final_hotspot_polygons_weighted.geojson\"\n",
        "\n",
        "try:\n",
        "    # 加载两个输入文件\n",
        "    gdf_dining_zones = gpd.read_file(FILE_DINING_ZONES)\n",
        "    gdf_weighted_hotspots = gpd.read_file(FILE_HOTSPOT_ARRIVALS_WEIGHTED)\n",
        "\n",
        "    # 确保 CRS 一致\n",
        "    gdf_dining_zones = gdf_dining_zones.to_crs(\"EPSG:4326\")\n",
        "    gdf_weighted_hotspots = gdf_weighted_hotspots.to_crs(\"EPSG:4326\")\n",
        "\n",
        "    # 执行空间相交\n",
        "    final_polygons_gdf = gpd.overlay(gdf_dining_zones, gdf_weighted_hotspots, how='intersection')\n",
        "    final_polygons_gdf = final_polygons_gdf[~final_polygons_gdf.geometry.is_empty]\n",
        "\n",
        "    final_polygons_gdf.to_file(OUTPUT_FILE_B, driver=\"GeoJSON\")\n",
        "    print(f\"--- 成功！脚本 B 已完成 ---\")\n",
        "    print(f\"识别出 {len(final_polygons_gdf)} 个最终融合的热点多边形。\")\n",
        "    print(f\"结果已保存到: {OUTPUT_FILE_B}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n!!! 致命错误: 找不到文件 {e.filename} !!!\")\n",
        "    print(\"请确保 'dining_zones.geojson' 和 'hotspot_arrival_areas_weighted.geojson' 存在。\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n!!! 脚本 B 失败: {e} !!!\")\n",
        "\n",
        "\n",
        "# --- (脚本 C) 生成餐厅数据库 ---\n",
        "print(\"\\n--- 开始执行脚本 C: 生成餐厅数据库 ---\")\n",
        "\n",
        "FILE_RESTAURANTS_CSV = \"restaurants_nyc_googlemaps.csv\"\n",
        "FILE_FINAL_POLYGONS_WEIGHTED = \"final_hotspot_polygons_weighted.geojson\"\n",
        "OUTPUT_FILE_C = \"restaurants_with_hotspot_scores.geojson\"\n",
        "\n",
        "try:\n",
        "    # 加载餐厅 CSV\n",
        "    df_restaurants = pd.read_csv(FILE_RESTAURANTS_CSV)\n",
        "    df_restaurants = df_restaurants.dropna(subset=['latitude', 'longitude'])\n",
        "\n",
        "    # 转换为 GeoDataFrame\n",
        "    gdf_restaurants = gpd.GeoDataFrame(\n",
        "        df_restaurants,\n",
        "        geometry=gpd.points_from_xy(df_restaurants.longitude, df_restaurants.latitude),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    print(f\"--- 成功加载 {len(gdf_restaurants)} 家餐厅 ---\")\n",
        "\n",
        "    # 加载最终的加权多边形\n",
        "    gdf_final_polygons = gpd.read_file(FILE_FINAL_POLYGONS_WEIGHTED)\n",
        "\n",
        "    # 仅保留用于连接的关键列 (和几何图形)\n",
        "    cols_to_keep = [\n",
        "        'zone', 'LocationID', 'Count_Lunch', 'Count_WkdyEve', 'Count_WkndEve',\n",
        "        'weighted_score', 'Zs', 'p_sim', 'geometry'\n",
        "    ]\n",
        "    # 过滤掉 gdf_final_polygons 中可能不存在的列\n",
        "    cols_to_keep_existing = [col for col in cols_to_keep if col in gdf_final_polygons.columns]\n",
        "    gdf_final_polygons_slim = gdf_final_polygons[cols_to_keep_existing]\n",
        "\n",
        "    # --- 核心：空间连接 (Spatial Join) ---\n",
        "    # 将多边形的属性 (如 weighted_score) 附加到在多边形内的餐厅点上\n",
        "    gdf_restaurants_tagged = gpd.sjoin(\n",
        "        gdf_restaurants,\n",
        "        gdf_final_polygons_slim,\n",
        "        how='left',\n",
        "        predicate='within' # Changed 'op' to 'predicate'\n",
        "    )\n",
        "\n",
        "    # 清理 sjoin 产生的 'index_right' 列\n",
        "    if 'index_right' in gdf_restaurants_tagged.columns:\n",
        "        gdf_restaurants_tagged = gdf_restaurants_tagged.drop(columns=['index_right'])\n",
        "\n",
        "    gdf_restaurants_tagged.to_file(OUTPUT_FILE_C, driver=\"GeoJSON\")\n",
        "    print(f\"\\n--- 成功！脚本 C 已完成 ---\")\n",
        "    print(f\"已将 {len(gdf_restaurants_tagged)} 家餐厅（包含已标记和未标记的）保存到 GeoJSON。\")\n",
        "    print(f\"最终餐厅数据库已保存到: {OUTPUT_FILE_C}\")\n",
        "\n",
        "    print(\"\\n--- 阶段二 (重新执行) 已全部完成 ---\")\n",
        "    print(\"您可以下载以下三个新文件：\")\n",
        "    print(f\"1. {FILE_HOTSPOT_ARRIVALS_WEIGHTED}\")\n",
        "    print(f\"2. {OUTPUT_FILE_B}\")\n",
        "    print(f\"3. {OUTPUT_FILE_C}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n!!! 致命错误: 找不到文件 {e.filename} !!!\")\n",
        "    print(\"请确保 'restaurants_nyc_googlemaps.csv' 和 'final_hotspot_polygons_weighted.geojson' 存在。\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n!!! 脚本 C 失败: {e} !!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpouVp3_avJ8",
        "outputId": "192f6bda-c5a1-4d6d-d067-42f1a7641d58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 开始执行脚本 B: 生成最终热点多边形 ---\n",
            "--- 成功！脚本 B 已完成 ---\n",
            "识别出 28 个最终融合的热点多边形。\n",
            "结果已保存到: final_hotspot_polygons_weighted.geojson\n",
            "\n",
            "--- 开始执行脚本 C: 生成餐厅数据库 ---\n",
            "--- 成功加载 14330 家餐厅 ---\n",
            "\n",
            "--- 成功！脚本 C 已完成 ---\n",
            "已将 14330 家餐厅（包含已标记和未标记的）保存到 GeoJSON。\n",
            "最终餐厅数据库已保存到: restaurants_with_hotspot_scores.geojson\n",
            "\n",
            "--- 阶段二 (重新执行) 已全部完成 ---\n",
            "您可以下载以下三个新文件：\n",
            "1. hotspot_arrival_areas_weighted.geojson\n",
            "2. final_hotspot_polygons_weighted.geojson\n",
            "3. restaurants_with_hotspot_scores.geojson\n"
          ]
        }
      ]
    }
  ]
}